


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score, precision_score
from sklearn.metrics import jaccard_score








raw_patients = pd.read_excel('patients.xlsx')
raw_patients.columns


raw_patients.head()


raw_patients = raw_patients[['Diagnose Arzt vor KI', 'Befund KI', 'Diagnose Arzt nach KI', 'Ã„nderung der Diagnose', 'Befund der Kinderradiologen']]
raw = raw_patients.copy(deep=True)
raw_patients.head()



for col in raw_patients.columns:
   print(raw_patients[col].value_counts())


negativ = ['keine','keien','Keine','no','No','nein','Kein','kein','nicht sicher frakturtyisch']

raw_patients.replace(negativ, 0, regex=True, inplace=True)
#Make sure there are no negative words left
for col in raw_patients.columns:
   print(f"column: {col}")
   print(raw_patients[col].value_counts())


binary_list = (raw_patients != 0)
binary_list = binary_list.astype(int)
patients = pd.DataFrame(binary_list)
patients.head()





doctor_diagnosis_beforeAi = np.array(patients['Diagnose Arzt vor KI'])
doctor_diagnosis_afterAi = np.array(patients['Diagnose Arzt nach KI'])
Ai_diagnosis = np.array(patients['Befund KI'])
Gold_standard = np.array(patients['Befund der Kinderradiologen'])


accuracy_doctor_diagnosis_beforeAi = accuracy_score(doctor_diagnosis_beforeAi, Gold_standard)
accuracy_doctor_diagnosis_afterAi = accuracy_score(doctor_diagnosis_afterAi, Gold_standard)
accuracy_Ai_diagnosis = accuracy_score(Ai_diagnosis, Gold_standard)
print(f'Accuracy of Doctors before Ai: {accuracy_doctor_diagnosis_beforeAi} \nAccuracy of Doctors after Ai: {accuracy_doctor_diagnosis_afterAi} \nAccuracy of Ai: {accuracy_Ai_diagnosis}')








from IPython.display import Image, display
display(Image(filename='Jaccard_index.png'))



display(Image(filename='Jaccard_index_formula.png'))


#Reference
#1:https://www.bing.com/images/search?view=detailV2&ccid=R7OeruOt&id=CB2FB34B1110AE0FF1504369C8D02F4902802B3B&thid=OIP.R7OeruOtIk4Js4jlp8C_dQHaE-&mediaurl=https%3a%2f%2fmiro.medium.com%2fv2%2fresize%3afit%3a744%2f1*XiLRKr_Bo-VdgqVI-SvSQg.png&cdnurl=https%3a%2f%2fth.bing.com%2fth%2fid%2fR.47b39eaee3ad224e09b388e5a7c0bf75%3frik%3dOyuAAkkv0MhpQw%26pid%3dImgRaw%26r%3d0&exph=500&expw=744&q=jaccard+index&simid=608054468191060378&FORM=IRPRST&ck=17E5E74F1F4F349D91B67B0005D091BA&selectedIndex=0&itb=0
#2: https://th.bing.com/th/id/R.f8431099301881554edc28275092be3c?rik=Pz98dUJWbx90IA&riu=http%3a%2f%2fblog.stratio.com%2fwp-content%2fuploads%2f2017%2f01%2fImage-2-%E2%80%93-Jaccard-Index-formula.png&ehk=mPsG%2bYR%2b49kvtHD9laZdGsHCT0Apk8rG6TbxQfQaddA%3d&risl=&pid=ImgRaw&r=0






jaccard_doctor_diagnosis_beforeAi = jaccard_score(doctor_diagnosis_beforeAi, Gold_standard)
jaccard_doctor_diagnosis_afterAi = jaccard_score(doctor_diagnosis_afterAi, Gold_standard)
jaccard_Ai_diagnosis = jaccard_score(Ai_diagnosis, Gold_standard)
print(f'Jaccard Index of Doctors before Ai: {jaccard_doctor_diagnosis_beforeAi} \nJaccard Index of Doctors after Ai: {jaccard_doctor_diagnosis_afterAi} \nJaccard Index of Ai: {jaccard_Ai_diagnosis}')





patients.head()


cm = confusion_matrix(doctor_diagnosis_beforeAi, Gold_standard)
print(cm)



import plotly.express as px
cm_df = pd.DataFrame(cm, index=["No Fracture", "Fracture"], columns=["No Fracture", "Fracture"])

# Plotly heatmap
fig = px.imshow(cm_df, text_auto=True, labels=dict(x="Predicted", y="Actual", color="Count"), 
                title="Confusion Matrix of doctor before Ai")
fig.show()





display(Image(filename='recall.png'))


recall = recall_score(doctor_diagnosis_beforeAi, Gold_standard)
print(f'Sensitivity (Recall): {recall}')





display(Image(filename='precision.png'))


precision = precision_score(doctor_diagnosis_beforeAi, Gold_standard)
print(f'Precision: {precision}')





display(Image(filename='f1score.jpg'))


f1 = f1_score(doctor_diagnosis_beforeAi, Gold_standard)  
print(f'F1 Score: {f1}')


cm = confusion_matrix(Ai_diagnosis, Gold_standard)
cm_df = pd.DataFrame(cm, index=["No Fracture", "Fracture"], columns=["No Fracture", "Fracture"])

# Plotly heatmap
fig = px.imshow(cm_df, text_auto=True, labels=dict(x="Predicted", y="Actual", color="Count"), 
                title="Confusion Matrix of Ai")
fig.show()


recall = recall_score(Ai_diagnosis, Gold_standard)
print(f'Sensitivity (Recall): {recall}')


precision = precision_score(Ai_diagnosis, Gold_standard)
print(f'Precision: {precision}')


f1 = f1_score(Ai_diagnosis, Gold_standard)
print(f'F1 Score: {f1}')





#number of fractures and no fractures in Gold_standard
#check if the data is balanced
patients['Befund der Kinderradiologen'].value_counts()
sns.barplot(x=patients['Befund der Kinderradiologen'].value_counts().index, y=patients['Befund der Kinderradiologen'].value_counts().values)

plt.title('Number of fractures and no fractures in Gold_standard')
plt.show()






sns.barplot(x=['Doctor before Ai', 'Doctor after Ai', 'Ai'], y=[accuracy_doctor_diagnosis_beforeAi, accuracy_doctor_diagnosis_afterAi, accuracy_Ai_diagnosis])
plt.title('Accuracy comparison between doctor diagnosi before and after Ai')
plt.show()





error_analysis = patients[patients['Diagnose Arzt vor KI'] != patients['Befund KI']]
print(f"Number of cases where doctor diagrees with Ai: {len(error_analysis)}")
error_analysis = error_analysis[error_analysis['Diagnose Arzt vor KI'] == error_analysis['Befund der Kinderradiologen']]
print(f"Number of cases where doctor diagrees with Ai and doctor is correct: {len(error_analysis)}")





doctor_changed = patients[patients['Diagnose Arzt vor KI'] != patients['Diagnose Arzt nach KI']]
print(f"Number of cases where doctor changed his diagnosis after Ai: {len(doctor_changed)}")



patients['change_in_procedure'] = patients['Diagnose Arzt vor KI'] != patients['Diagnose Arzt nach KI']
# Add a new column to indicate AI agreement
patients['ai_agreement'] = patients['Befund KI'] == patients['Diagnose Arzt vor KI']
patients['ai_agreement'] = patients['ai_agreement'].replace({True: 'Agree', False: 'Disagree'})
summary = patients.groupby(['ai_agreement', 'change_in_procedure']).size().unstack(fill_value=0)
print(summary)



summary.plot(kind='bar', stacked=True)

plt.title('Impact of AI Agreement on Doctor\'s Procedure Changes')
plt.xlabel('AI Agreement (1 = Agree, 0 = Disagree)')
plt.ylabel('Count of Procedure Changes (1 = Change, 0 = No Change)')
plt.xticks(rotation=0)  # Rotate x labels for better readability
plt.legend(title='Procedure Change', labels=['No Change', 'Change'], loc='upper right')
plt.show()





before = (doctor_changed['Diagnose Arzt vor KI'] == doctor_changed['Befund der Kinderradiologen']).sum()
after = (doctor_changed['Diagnose Arzt nach KI'] == doctor_changed['Befund der Kinderradiologen']).sum()
print(f"Number of cases where doctor changed his diagnosis to correct ones: {after-before}")








check = (patients['Befund KI'] != patients['Befund der Kinderradiologen'])
raw['Befund der Kinderradiologen'].value_counts()
incorrect['Befund der Kinderradiologen'].value_counts()







